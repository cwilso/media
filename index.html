<!DOCTYPE html>
<html>
<head>
  <title>Media APIs for the Multi-platform Web</title>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="chrome=1">
  <!--<meta name="viewport" content="width=device-width, initial-scale=1.0, minimum-scale=1.0">-->
  <!--<meta name="viewport" content="width=device-width, initial-scale=1.0">-->
  <!--This one seems to work all the time, but really small on ipad-->
  <!--<meta name="viewport" content="initial-scale=0.4">-->
  <meta name="apple-mobile-web-app-capable" content="yes">
  <link rel="stylesheet" media="all" href="theme/css/default.css">
  <link rel="stylesheet" media="only screen and (max-device-width: 480px)" href="theme/css/phone.css">
  <base target="_blank"> <!-- This amazingness opens all links in a new tab. -->
  <script data-main="js/slides" src="js/require-1.0.8.min.js"></script>
</head>
<body style="opacity: 0">

<slides class="layout-widescreen">

<!--
<slide class="logoslide nobackground">
  <article class="flexbox vcenter">
    <div style='margin: 0 0 2em 0'><img src="images/google_developers_logo.png" alt="Google developers logo"></div>
  </article>
</slide>
-->

<slide class="title-slide segue nobackground">
  <aside class="gdbar"><img src="images/google_developers_icon_128.png"></aside>
  <!-- The content of this hgroup is replaced programmatically through the slide_config.json. -->
  <hgroup class="auto-fadein">
    <h1 style="width: 70%; margin: 0 0 0.5em 0;" data-config-title><!-- populated from slide_config.json --></h1>
    <!-- <h2 data-config-subtitle>populated from slide_config.json</h2> -->
    <p data-config-presenter><!-- populated from slide_config.json --></p>
    <p><a href="http://twitter.com/cwilso" title="Chris Wilson on Twitter">@cwilso</a></p>
  </hgroup>
  <aside class="note">
    <p>Good morning.  I'm Chris Wilson, developer advocate for Chrome at Google, and we're here to talk about the richness of the modern web media platform - APIs spanning video, audio and realtime communication.</p>
  </aside>
</slide>


<slide class="nobackground">
    <article class="fill flexbox vcenter">
      <div class='big'><a href="http://goo.gl/lzhB1Y" title="These slides online">http://goo.gl/lzhB1Y</a></div>
    </article>
    <aside class="note">
      <p>Incidentally, this deck is live on the web, so you can follow along or refer to it later.</p>
      <p>There are lots of links in the slides - I hope these are useful, online if not on screen.</p>
    </aside>
</slide>


<slide class="nobackground">
    <article class="fill flexbox vcenter">
      <div class="big red" style="font-weight: bold">Two major trends</div>
    </article>
    <aside class="note">
      <p>As a subtext, there are two main trends driving the developments in the web media platform for the past couple of years.</p>
      <p>The first is obvious - who in the crowd does NOT have a smartphone or tablet with them?  Now, who does NOT have a laptop with them?</p>
    </aside>
</slide>

<slide class="nobackground">
    <article class="fill flexbox vcenter">
      <div class="big">Trend 1: <br>Computing means Mobile.</div>
    </article>
    <aside class="note">
      <p>I expect those numbers to keep shifting toward mobile.  Computing is very quickly moving away from the monitor + keyboard + mouse configuration.</p>
    </aside>
</slide>


<slide class="nobackground">
    <article class="fill flexbox vcenter main">
      <p>53% of adults media multi-task while watching TV</p>
    </article>
    <footer class="source">Source: <a href="http://media.ofcom.org.uk/2013/08/01/the-reinvention-of-the-1950s-living-room-2/" title="OFCOM report on TV viewing habits in the UK">The reinvention of the 1950s living room, OFCOM August 2013</a></footer>
    <aside class="note">
      <p>In addition, the second-screen phenomenon is quite strong.  A study from last year in the UK showed that more that half of UK adults would multi-task with other media - like checking email or looking up information on shows.</p>
    </aside>
</slide>

<slide class="nobackground">
    <article class="fill flexbox vcenter">
      <div class="big">Trend 2: <br>Video is HUGE.</div>
    </article>
    <aside class="note">
      <p>The second trend is that video delivered over the Internet is immensely popular.  I KNOW, I was shocked too when I read this on my smartphone while I was marathon-watching breaking bad on netflix.</p>
    </aside>
</slide>



<slide class="nobackground">
  <article  class="fill flexbox vcenter main">
    <p>Video will be 80-90% of net traffic by 2017.</p>
  </article>
  <footer class="source">Source: <a href="http://goo.gl/RfB73h" title="Cisco networking forecast">Cisco Visual Networking Index: Forecast and Methodology, 2012–2017</a></footer>
  <aside class="note">
    <p>In 2017, video be in the range of 80 to 90 percent of global traffic.  Every second, nearly a million minutes of video content will cross the network.</p>
    <p>We're coming to expect seamless audio, video and realtime communication from apps, games and sites - on a range of devices.</p>
  </aside>
</slide>

<slide class="fill nobackground" style="background-image: url(images/evolution.png)">
  <aside class="note">
    <p>Now the great thing is that the web platform has been adding APIs to push the limits of what you can do in the mobile browser, particularly around graphics, media and interactivity, for some time now.</p>
 </aside>
</slide>

<slide class="nobackground">
<hgroup>
    <h2 style="color: black; font-family: 'Faith Collapsing'; font-size: 200%; letter-spacing: 1.1px">Ye olde Flashe vid</h2>
</hgroup>
<article>
    <pre style="background: none; color: black; font-family: 'Faith Collapsing'; font-size: 0.9em; letter-spacing: 1.1px; line-height: 1.2em">
&lt;object classid="clsid:d27cdb6e-ae6d-11cf-96b8-444553540000" width="425" height="344"
  codebase="http://download.macromedia.com/pub/shockwave/cabs/flash/
  swflash.cab#version=6,0,40,0"&gt;
  &lt;param name="allowFullScreen" value="true" /&gt;
  &lt;param name="allowscriptaccess" value="always" /&gt;
  &lt;param name="src" value="http://www.eurgh.com/v/oHg5SJYRHA0&hl=en&fs=1&" /&gt;
  &lt;param name="allowfullscreen" value="true" /&gt;
  &lt;embed type="application/x-shockwave-flash" width="425" height="344"
    src="http://www.eurgh.com/v/oHg5SJYRHA0&hl=en&fs=1&"
    allowscriptaccess="always" allowfullscreen="true"&gt;
  &lt;/embed&gt;
&lt;/object&gt;
    </pre>
  </article>
  <footer class="source">Source: <a href="http://html5doctor.com/the-video-element/" title="HTML5 Doctor blog post">HTML5 Doctor</a></footer>
  <aside class="note">
    <p>To start with, we've thankfully replaced this way of doing video...</p>
  </aside>
</slide>

<slide class="nobackground">
  <article  class="fill flexbox vcenter">
    <pre class="quiteBig prettyprint" style="background: none;">&lt;video src='chrome.webm' /&gt;</code>
  </article>
  <aside class="note">
    <p>...with this.  And all modern browsers support the HTML5 video element.</p>
  </aside>
</slide>

<slide class="segue dark nobackground">
  <aside class="gdbar"><img src="images/google_developers_icon_128.png"></aside>
  <hgroup class="auto-fadein">
    <h2 style="width: 780px">Codecs for the modern Web</h2>
  </hgroup>
  <aside class="note">
    <p>Now, of course, we couldn't do any of this without codecs.</p>
    <p>With the rise and rise of media on mobile platforms, codec performance is absolutely crucial to the future of the web.</p>
    <p>So -- a word about the work that's being done at Google on open source codecs.</p>
  </aside>
</slide>

<slide>
  <hgroup>
    <h2>VP8 and VP9: Open codecs for the web</h2>
  </hgroup>
  <article>
  <ul>
    <li>VP8 built into devices - including camera chips</li>
    <li><a href="http://wiki.webmproject.org/hardware/arm-socs">Systems with dedicated VP8 support</a></li>
    <li><a href="http://localhost/vp9/index.html" title="VP9/H.264 comparison">VP9 v H.264: Google I/O</a></li>
  </ul>
  </article>
  <aside class="note">
    <p>Our VP9 demo shows that we're using  better than 50% fewer bits than H.264 as well.</p>
    <p>Expect first chips supporting VP9 decode probably second half of 2014.</p>
  </aside>
</slide>


<slide class="nobackground">
  <article class="fill flexbox vcenter">
    <pre class="quiteBig prettyprint" style="background: none;">
&lt;video&gt;
  &lt;source src="chrome.webm" /&gt;
  &lt;source src="chrome.mp4" /&gt;
&lt;/video&gt;
    </pre>
  </article>
  <aside class="note">
    <p>Now, not everyone supports WebM and VP8 - notably, Safari and IE do not - but using the source element enables the browser to automatically select the video src, and just two formats cover all the browsers - so this is still pretty straightforward.</p>
  </aside>
</slide>

<slide class="nobackground">
  <article class="fill flexbox vcenter">
    <pre class="quiteBig prettyprint" style="background: none;">
&lt;video&gt;
  &lt;source src="chrome.webm" 
      <b>type="video/webm"</b> /&gt;
  &lt;source src="chrome.mp4" 
      <b>type="video/mp4"</b> /&gt;
&lt;/video&gt;
    </pre>
  </article>
  <aside class="note">
  <p>You might want to add the optional type attribute, since that way your app won't need to serially download the beginning of each file until it finds one it can play.</p>
</p></aside>
</slide>


<slide class="nobackground">
  <article class="fill flexbox vcenter">
    <pre class="quiteBig prettyprint" style="background: none;">
&lt;video <b>poster="images/poster.jpg</b>"&gt;
  &lt;source src="chrome.webm" 
      type="video/webm" /&gt;
  &lt;source src="chrome.mp4" 
      type="video/mp4" /&gt;
&lt;/video&gt;
    </pre>
  </article>
  <aside class="note"><p>And finally, particularly on mobile, it's useful to add a poster image - a placeholder picture.  This means another download, but on mobile particularly it gives a better experience...</p></aside>
</slide>

<slide class="nobackground">
  <article >
    <pre class="quiteBig prettyprint" style="background: none;">
&lt;video poster="images/poster.jpg"
  <b>autoplay preload="metadata"</b>&gt;
  &lt;source src="chrome.webm" 
      type="video/webm" /&gt;
  &lt;source src="chrome.mp4" 
      type="video/mp4" /&gt;
&lt;/video&gt;
    </pre>
    <div><a href="http://stevesouders.com/tests/mediaevents.php" title="Steve Souders article about video preload buffer length">Steve Souders' preload test</a></div>
  </article>
  <aside class="note">
    <p>Because there are two video features that DON'T work on mobile... I don't know of any mobile browser that supports autoplay, or scripting playback control prior to the user interacting with the page.</p>
<p>And preload also doesn't work – on desktop this can be used to buffer video, but mobile browsers typically reserve downloading until the user initiates playback.</p>
  </aside>
</slide>

<slide class="segue dark nobackground">
  <aside class="gdbar"><img src="images/google_developers_icon_128.png"></aside>
  <hgroup class="auto-fadein">
    <h2 style="width: 780px">Advanced video features</h2>
  </hgroup>
  <aside class="note">
    <p>But aside from these basics, video isn't just a black-box embedded object anymore.  Just to show how far we've come with video on the web, let's talk about some of the ways video is opened up as a programmable tool.</p>
  </aside>
</slide>


<slide>
  <article class="fill flexbox vcenter">
    <div class="demoLabel">Alpha transparency</div>
    <p class="big" style="margin: 0 0 1.5em 0;"><a href="http://simpl.info/alpha" title="WebM alpha transparency demo">simpl.info/alpha</a></p>
    <div style="font-size: 70%"><a href="http://updates.html5rocks.com/2013/07/Alpha-transparency-in-Chrome-video" title="HTML5 Rocks Update about alpha transparancy in WebM">HTML5 Rocks update</a></div>
  </article>
  <aside class="note">
    <p>First, here's a demo of using alpha transparency.  You can let the browser do your green screen compositing!</p>
  </aside>
</slide>


<slide>
  <article class="fill flexbox vcenter">
    <div class="demoLabel">Captions and subtitles</div>
    <p class="quiteBig" style="margin: 0 0 1em 0"><a href="http://simpl.info/track" title="Track element video demo">simpl.info/track</a></p>
    <p class="quiteBig"><a href="http://simpl.info/track/audio" title="Track element audio demo">simpl.info/track/audio</a></p>
  </article>
  <aside class="note">
    <p>Next, HTML5 video can have timed metadata associated with it; this greatly enhances video accessibility.
    <p>The track element allows you to display captions or subtitles from a VTT or SRT file. They're rendered over the video element.</p>
    <p>The track element is supported on Internet Explorer, and in Chrome for Android and desktop, and Safari on Mac OS.</p>
  </aside>
</slide>

<slide class="nobackground">
  <article  class="fill flexbox vcenter">
    <pre class="biggish prettyprint" style="background: none;">
&lt;video poster="images/poster.jpg"
  autoplay preload="metadata"&gt;
  &lt;source src="chrome.webm" type="video/webm" /&gt;
  &lt;source src="chrome.mp4" type="video/mp4" /&gt;
  <b>&lt;track src="<a href="http://simpl.info/track/tracks/developerStories-subtitles-en.vtt" title="Example of a VTT file">track.vtt</a>" /&gt;</b>
  &lt;p&gt;Video element not supported.&lt;/p&gt;
&lt;/video&gt;
    </pre>
    <div><a href="http://www.w3.org/community/texttracks/2012/09/26/webvtt-in-media-transport-formats/" title="In-band WebVTT information">In-band WebVTT: track data </a></div>
  </article>
  <aside class="note">
    <p>You do this by associating a WebVTT file with the video.  In-band WebVTT is also supported now by Chrome: WebVTT information packaged with a video file. </p>
    <p>This makes it possible to store video with timed metadata of any kind.</p>
  </aside>
</slide>

<slide class="nobackground">
  <article  class="fill flexbox vcenter">
    <div class="demoLabel">Media Fragments</div>
  <div class="big"><a href="http://www.simpl.info/mf" title="Media Fragments demo">simpl.info/mf</a></div>
  <pre class="prettyprint" style="background: none; font-size: 150%; margin-top: 1.5em;" >&lt;video src='chrome.webm<b>#t=5,10</b>' /&gt;</pre>
  </article>
  <aside class="note">
    <p>On the same timing front, we can use Media Fragments to specify what range of the video we want to play.  This gives us a way to refer to only part of a video - which is nice, because you only need to download the part of the video you want to watch.  This enables you to deliver multiple views on the same video - chapters, or even video sprites, so to speak - without having to encode and serve multiple files.</p>
    <p>Again, this is really well supported on mobile and desktop -- though sadly not on iOS, last time I looked,  and you need to make sure Range Requests are supported by your server.</p>
  </aside>
</slide>



<slide>
  <article class="fill flexbox vcenter">
    <div class="demoLabel">Deep linking, deep search</div>
    <p class="big"><a href="http://simpl.info/search" title="Chrome video search">simpl.info/search</a></p>
  </article>
  <aside class="note">
    <p>WebVTT and the track element give us a huge improvement in the accessibility of media, but they have some nice side effects as well.</p>
    <p>Once we have captions with times, and the ability to refer to a place in the video with Media Fragments, we can do cool stuff with search and navigation.  Let's give this a try - this app pulls in all the metadata from hundreds of Chrome videos, like our various talks at past Google IO conferences - and let's say I want to see if anyone's ever played the ukulele during a Chrome talk...</p>
  </aside>
</slide>

<!--
<slide>
  <article class="fill flexbox vcenter">
    <code><a href="http://http://video.google.com/timedtext?lang=en&format=vtt&v=p2HzZkd2A40" title="YouTube VTT caption file for Google I/O 2013 WebRTC presentation">video.google.com/timedtext?lang=en&format=vtt&v=p2HzZkd2A40</a></code>
  </article>
  <aside class="note">
    <p>By the way, if you want to hack something yourself, here's the URL for a YouTube caption file.</p>
  </aside>
</slide>
-->

<slide>
  <article class="fill flexbox vcenter">
    <div class="demoLabel">Synchronised metadata</div>
    <p class="big"><a href="http://simpl.info/track/map" title="Synchronised video, Google Map and Street View">simpl.info/map</a></p>
  </article>
  <aside class="note">
    <p>It's also important to note that timed text tracks aren't just for subtitles and captions - we can also put data in cues.</p>
    <p>In this example, a Googler cycled around the Mountain View campus and shot video and got GPS coordinates.  This app turns that data into a track file, where each cue is actually a chunk of JSON with latlong and video time data.</p>
    <p>As each cue is fired, the data is read and the map and Street View updated to match.  And I can click on the map, and the closest cue is found, and the video jumped to that point.</p>
  </aside>
</slide>


<slide>
  <article class="fill flexbox vcenter">
    <div class="demoLabel">Media Source Extensions</div>
    <div class="small">(generating streams from JavaScript)</div>
    <p class="big"><a href="http://simpl.info/mse" title="Media Source Extensions demo">simpl.info/mse</a></p>
    <!-- <p><a href="w3.org/TR/media-source" title="MSE spec">Spec</a></p> -->
<!--     <p><a href="updates.html5rocks.com/2011/11/Stream-video-using-the-MediaSource-API" title="Short MSE article on HTML5 Rocks">HTML5 Rocks Update</a></p>
 -->  </article>
  <aside class="note">
    <p>MSE enables JavaScript to build streams for playback from chunks of video.</p>
    <p>This use cases such as adaptive streaming and time shifting - all driven by JS.</p>
  </aside>
</slide>

<slide class="nobackground">
  <article  class="fill flexbox vcenter">
    <div class="demoLabel">Adaptive Streaming</div>
    <div class="big" style="margin: 0 0 1em 0;"><a href="http://dash-mse-test.appspot.com/dash-player.html?url=http://yt-dash-mse-test.commondatastorage.googleapis.com/media/car-20120827-manifest.mpd" title="Sample DASH Player">DASH</a></div>
    <div><a href="http://www.bbc.co.uk/rd/blog/2013/09/mpeg-dash-test-streams" title="DASH at the BBC">What is DASH?</a></div>
  </article>
  <aside class="note">
    <p>DASH allows streaming of media over HTTP, somewhat like Apple's HTTP Live Streaming.</p>
  </aside>
</slide>

<slide>
  <article  class="fill flexbox vcenter">
    <div class="demoLabel">EME: Encrypted Media Extensions</div>
    <ul>
      <li><a href="http://www.w3.org/TR/encrypted-media/" title="Encrypted Media Extensions W3C Working Draft">Spec</a></li>
      <li><a href="http://dash-mse-test.appspot.com" title="">YouTube demo</a></li>
      <li><a href="http://techblog.netflix.com/2013/04/html5-video-at-netflix.html" title="HTML5 Video at Netflix">Netflix on Chrome OS</a></li>
      <li><a href="http://downloads.webmproject.org/adaptive-encrypted-demo/adaptive/index.html" title="WebM encrypted+adaptive demo">WebM encrypted + adaptive demo</a></li>
    </ul>
  </article>
  <aside class="note">
    <p>And finally in video features, I want to briefly mention EME - encrypted media extensions.  EME is a JavaScript API extending the HTMLMediaElement APIs, that enables web applications to interact with DRM systems, in order to negotiate playback of encrypted media, either using simple ClearKey encryption or an add-on DRM module, such as WideVine.</p>
    <p>Browsers that support EME can detect that a video is encrypted and use a Content Decryption Module to obtain a key and play back the decrypted content.  The goal here is to enable an acceptable platform for high-value content - like high-definition current movies or TV shows, where the contracts require such protections.</p>
  </aside>
</slide>



<slide class="segue dark nobackground">
  <aside class="gdbar"><img src="images/google_developers_icon_128.png"></aside>
  <hgroup class="auto-fadein">
    <h2 style="width: 780px">Local media input</h2>
  </hgroup>
  <aside class="note">
    <p>That was the basics of the video platform, now let’s talk about creating!  The first step we need to take is to get video and audio into the computer - via the webcam and microphone in your laptop or mobile device, for example.</p>
    <p>We can do just that with an API called getUserMedia().</p>
  </aside>
</slide>

<slide>
  <hgroup>
    <h2>getUserMedia</h2>
    <h3>It's pretty simple.</h3>
  </hgroup>
  <article>
    <pre class="prettyprint" data-lang="javascript">
var constraints = {video: true};

function successCallback(stream) {
  var video = document.querySelector("video");
  video.src = window.URL.createObjectURL(stream);
}

function errorCallback(error) {
  console.log("navigator.getUserMedia error: ", error);
}

<b>navigator.getUserMedia(constraints, successCallback, errorCallback);</b>
</pre>
  </article>
  <aside class="note">
    <p>getUserMedia() is pretty simple - you pass in a constraint object saying what user media you're interested in, and if the user gives permission, you get a stream back..</p>
  </aside>
</slide>


<slide class="nobackground">
  <article class="fill flexbox vcenter">
    <div class="big"><a href="http://www.simpl.info/gum" title="Simple getUserMedia demo">simpl.info/gum</a></div>
  </article>
  <aside class="note">
    <p>You can then do different things with that video stream - most simply, you can assign it to a video SRC attribute, and display it live!</p>
  </aside>
</slide>


<slide>
  <article class="fill flexbox vcenter">
    <div style="margin: 0 0 1em 0; font-weight: bold">gUM + Canvas</div>
    <div class="quiteBig"><a href="http://idevelop.github.com/ascii-camera/" title="getUserMedia video rendered as ASCII art">idevelop.github.com/ascii-camera</a></div>
  </article>
  <aside class="note">
  <p>gUM gets interesting when plugged into other APIs.</p>
  <p>This page is frame-grabbing images from the gUM video, and then analysing each pixel and turning it into ASCII.</p>
  </aside>
</slide>

<slide>
  <hgroup>
  </hgroup>
    <article class="fill flexbox vcenter">
      <div style="margin: 0 0 1em 0; font-weight: bold">Select resolution</div>
      <div class="quiteBig"><a href="https://simpl.info/res" title="getUserMedia constraints demo">simpl.info/res</a></div>
    </article>
    <aside class="note">
      <p>You also have the ability to choose constraints that select different resolutions and other features of the stream.</p>
    </aside>
</slide>

<slide>
  <hgroup>
  </hgroup>
    <article class="fill flexbox vcenter">
      <div style="margin: 0 0 1em 0; font-weight: bold">Select mic and camera</div>
      <div  class="quiteBig" style="margin: 0 0 2em 0;"><a href="https://simpl.info/sources" title="getUserMedia sources demo">simpl.info/sources
</a></div>
      <div style="font-size: 70%"><a href="https://play.google.com/store/apps/details?id=com.chrome.beta" title="Google Play: install Chrome Beta for Android">Install Chrome Beta for Android</a></div>
    </article>
    <aside class="note">
      <p>And of course you can choose what media source to use, too. These are supported in Android Chrome too, BTW.</p>
    </aside>
</slide>


<!-- <slide>
  <hgroup>
    <h2>Work underway to make this more user-focused</h2>
  </hgroup>
  <article>
    <ul>
      <li>User wants to choose "front-facing" or "rear-facing" camera, not a USB ID!</li>
      <li>Choose source: <a href="http://www.w3.org/TR/mediacapture-streams/#video-facing-mode-enum" title="W3C facing mode draft spec">spec</a></li>
      <li>Apply constraints dynamically from JavaScript: <a href="http://www.w3.org/TR/mediacapture-streams/#widl-MediaStreamTrack-applyConstraints-void-MediaTrackConstraints-constraints" title="W3C applyConstraints() draft spec">spec</a></li>
    </ul>
  </article>
  <aside class="note">
  <p></p>
    <p>Specs are being drafted to give more options for choosing devices,  resolutions and other constraints.</p>
    <p>Generic device choice, e.g. user-facing camera: not specific device ID.</p>
    <p>Selfie mode!</p>
    <p>With applyConstraints(): width, height, framerate, facingMode, etc.</p>
  </aside>
</slide> -->

<slide>
  <hgroup>
    <h2>gUM screencapture!</h2>
  </hgroup>
  <article>
    <p style="margin: 0 0 3em 0;">Be sure to enable <a href="chrome://flags/#enable-usermedia-screen-capture">screen capture support in getUserMedia</a>!</p>
    <pre class="prettyprint" data-lang="javascript">
var constraints = {
  video: {
    mandatory: {
      chromeMediaSource: 'screen'
    }
  }
};

navigator.getUserMedia(constraints, gotStream);
</pre>
  </article>
  <aside class="note">
    <p>Chrome has extended usermedia with two other sources that I hope will be picked up in the standard soon, too - screen capture is the first, to share your screen with other users or take screen caps...
  </aside>
</slide>

<slide class="nobackground">
  <article class="fill flexbox vcenter">
    <div style='margin: 0 0 2em 0'><a href="https://html5-demos.appspot.com/static/getusermedia/screenshare.html" title="Screen sharing demo">Screen sharing</a></div>
    <div><a href="http://updates.html5rocks.com/2012/12/Screensharing-with-WebRTC" title="HTML5 Rocks update demoing tab capture">Tab capture: chrome.tabCapture</a></div>
  </article>
  <aside class="note">
  <p>And we also have tab capture.  Note both of these are live streams - you can do a screencap, but you can also share this, for example, with a remote video feed!</p>
  </aside>
</slide>


<slide class="segue dark nobackground">
  <aside class="gdbar"><img src="images/google_developers_icon_128.png"></aside>
  <hgroup class="auto-fadein">
    <h2 style="width: 780px">WebRTC</h2>
  </hgroup>
  <aside class="note">
    <p>So - we have the ability to do great things with audio and video on the client - but we need to communicate these streams with others.  For this we have WebRTC, and this is one of the most ambitious and maybe disruptive web features in recent years. WebRTC provides realtime communication features in the open web platforms - no plugins or proprietary codecs, free for users and developers to use.</p>
    <p>If you're interested in WebRTC, I hope you caught Lisa Larson-Kelley's talk yesterday at 11; if not, I'll cover some high points.</p>
  </aside>
</slide>

  </aside>
</slide>

<slide class="nobackground">
    <article class="fill flexbox vcenter">
      <div class='big'><a href="https://apprtc.appspot.com/">Peer to peer</a></div>
    </article>
    <aside class="note">
      <p>WebRTC is designed as a peer-to-peer communication system for video, audio and data.</p>
    </aside>
</slide>

<slide class="nobackground">
  <hgroup>
    <h2>WebRTC across platforms</h2>
  </hgroup>
  <article style="height: 100%; position: relative">
    <ul class="tight" xstyle='margin: 0 1em 0 0'>
      <li><a href="http://apprtc.appspot.com">Chrome and Chrome for Android</a></li>
      <li>Firefox and Firefox for Android</li>
      <li>Opera</li>
      <li style="line-height: 1.4em;">Native <a href="https://code.google.com/p/libjingle/source/browse/trunk/talk/app/webrtc/java/src/org/webrtc/PeerConnection.java">Java</a> and Objective-C bindings<br />(<a href="https://code.google.com/p/webrtc/source/browse/trunk/talk/examples/ios/README?" title="Example iOS client for apprtc.appspot.com">example app</a>, <a href="https://code.google.com/p/webrtc/source/browse/trunk/talk/app/webrtc/objc/README" title="README file for Objective-C implementation of RTCPeerConnection">API</a>)</li>
    </ul>
    <img src="images/android.jpg" alt="Firefox/Chrome interoperability" style="position: absolute; right: 2em; top: -82px; width: 320px" />
    <img src="images/firefoxChrome.jpg" alt="Firefox/Chrome interoperability" style="position: absolute; bottom: 5em; width: 45%;" />
  </article>
  <aside class="note">
    <p>And Chrome, Firefox and Opera all implement WebRTC; in fact, Chrome and Firefox implement WebRTC on Android, too!  Let's take a look; I'm going to load up our webRTC chat demo, and now I'll go to the same site on my mobile... Wave to yourselves!</p>
  </aside>
</slide>

<slide class="nobackground">
  <article class="fill flexbox vcenter">
       <div class="big" style="margin: 0 0 0.3em 0;"><b>1,000,000,000+</b></div>
       <div>WebRTC endpoints</div>
  </article>
  <aside class="note">
  <p>This means we have over one billion WebRTC-enabled users today, which gives some idea of the size of this opportunity. In order to grow the ecosystem further, we're also providing official, supported native libraries for WebRTC for Android, and iOS.</p>
  </aside>
</slide>

<slide class="segue dark nobackground">
  <aside class="gdbar"><img src="images/google_developers_icon_128.png"></aside>
  <hgroup class="auto-fadein">
    <h2>What do we need for RTC?</h2>
    <h3></h3>
  </hgroup>
  <aside class="note">
    <p>So that's the vision for WebRTC. Now let's dig into how WebRTC works.</p>
  </aside>
</slide>

<slide>
  <hgroup>
    <h2>Four main tasks</h2>
  </hgroup>
    <article>
  <ul>
    <li>Acquiring audio and video</li>
    <li>Establishing a connection between peers (signaling)</li>
    <li>Communicating audio and video</li>
    <li>Communicating arbitrary data</li>
  </ul>
    </article>
    <aside class="note">
    <p></p>
    </aside>
</slide>

<slide>
  <hgroup>
    <h2>Three main JavaScript APIs</h2>
  </hgroup>
  <article>
  <ul>
    <li>MediaStreams (aka getUserMedia)</li>
    <li>RTCPeerConnection</li>
    <li>RTCDataChannel</li>
  </ul>
  </article>
  <aside class="note">
  </aside>
</slide>


<slide>
  <hgroup>
    <h2>Communicate Media Streams</h2>
  </hgroup>
  <article class="fill flexbox vcenter">
    <div>
      <img style="float: left; width: 27%;" src="images/caller.jpg" alt="WebRTC video chat: caller" />
      <div style="float: left; line-height: 2em; margin: 0 2em 0 2em; text-align: center;">
      →<br />
      getUserMedia<br />
      +<br />
      RTCPeerConnection<br />
      ←
      </div>
      <img  style="float: left; position: relative; top: 38px; width: 35%;" src="images/callee.jpg" alt="WebRTC video chat: callee" />
    </div>
  </article>
  <aside class="note">
    On the surface, the API is simple - get access to MediaStreams via getUserMedia, then plug them into a PeerConnection, and they will get sent to another WebRTC endpoint automatically. And when we receive media from the remote side, this goes into new MediaStreams that can be rendered in our web page.  Of course, setting up that connection is quite a bit more involved.
  </aside>
</slide>

<slide>
  <hgroup>
    <h2>WebRTC architecture</h2>
  </hgroup>
  <article class="flexbox vcenter">
    <img src="images/webrtcArchitecture.png" alt="WebRTC architecture diagram" />
  </article>
  <aside class="note">
    <p>Under the hood though, RTCPeerConnection is doing a lot - processing audio and video to remove noise, compressing the data using codecs, setting up the peer to peer pathway through NATs and firewalls, encrypting the data, ensuring we use the right amount of bandwidth...</p>
    <p>There's a lot of moving parts under the hood. Fortunately, with RTCPeerConnection, this is mostly abstracted away. You create a RTCPeerConnection, add your own MediaStreams to it, call a couple methods to set up the right parameters for the call, and off you go.</p>
  </aside>
</slide>

<slide class="nobackground">
  <article class="fill flexbox vcenter">
    <div style="margin: 0 0 2em 0; font-weight: bold">RTCPeerConnection without signaling</div>
    <div class="big"><a href="http://www.simpl.info/pc" title="Simple one-page RTCPeerConnection example">simpl.info/pc</a></div>
  </article>
  <aside class="note">
    <p>If you want to understand how WebRTC works, it's good to learn about RTCPeerConnection first, before you try to get your head around signaling mechanisms.</p>
    <p>This 'single page' demo does just that.</p>
    <p>It's very verbose: take a look at the console.</p>
    <p>Also take a look at chrome://webrtc-internals.</p>
  </aside>
</slide>

<slide class="nobackground">
    <article class="fill flexbox vcenter">
      <div style="margin: 0 0 2em 0; font-weight: bold">The canonical, full-fat video chat app!</div>
      <div class='big'><a href="http://apprtc.appspot.com" title="Canonical RTCPeerConnection videochat example">apprtc.appspot.com</a></div>
    </article>
    <aside class="note">
    <p>This is the best place to start with a fully featured WebRTC app: RTCPeerConnection, with signaling provided by XHR and the Google Channel API.</p>
    </aside>
</slide>



<slide class="segue dark nobackground">
  <aside class="gdbar"><img src="images/google_developers_icon_128.png"></aside>
  <hgroup class="auto-fadein">
    <h2>RTCDataChannel</h2>
    <h3>Bidirectional communication of arbitrary data between peers</h3>
  </hgroup>
  <aside class="note">
    <p>The last API to talk about is RTCDataChannel.  </p>
  </aside>
</slide>

<slide>
  <hgroup>
    <h2>Communicate arbitrary data</h2>
  </hgroup>
  <article class="fill flexbox vcenter">
  <div>

  <div style="float: left; width: 28%;">
    <img style="display: block; margin: 0 0 0.5em 0; position: relative; width: 100%;" src="images/jankInvadersScreenshot.jpg" alt="Game: caller" />
    <div style="background: #eee; font-family: 'Source Code Pro', 'Courier New', monospace; font-size: 0.5em; line-height: 1.2em; padding: 1em; white-space: pre;">onreceivemessage = handle(data);
...
var myData = [
  {
    id: "ship1";
    x: 24,
    y: 11,
    velocity: 7
  },
  ....
]
send(myData);
</div>
      </div>
      <div style="float: left; line-height: 2em; margin: 0 2em 0 2em; position: relative; text-align: center; top: 4em; width: 25%;">
      →<br />
      RTCDataChannel<br />
      +<br />
      RTCPeerConnection<br />
      ←
      </div>

      <div style="float: left; width: 28%;">
        <div style="background: #eee; font-family: 'Source Code Pro', 'Courier New', monospace; font-size: 0.5em; line-height: 1.2em; margin: 0 0 1em 0; padding: 1em; white-space: pre;">onreceivemessage = handle(data);
...
var myData = [
  {
    id: "ship7";
    x: 19,
    y: 4,
    velocity: 18
  },
  ....
]
send(myData);
</div>
        <img style="display: block; width: 100%;" src="images/jankInvadersScreenshotReversed.jpg" alt="Game: callee" />
      </div>

  </div>
  </article>
  <aside class="note">
  </aside>
</slide>

<slide>
  <hgroup>
    <h2>RTCDataChannel</h2>
  </hgroup>
  <article>
    <ul>
      <li>Same API as WebSockets</li>
      <li>Ultra-low latency</li>
      <li>Optionally unreliable or reliable (UDP)</li>
      <li>Secure</li>
    </ul>
  </article>
    <aside class="note">
    </aside>
</slide>

<slide class="nobackground">
    <article class="fill flexbox vcenter">
      <div style="margin: 0 0 2em 0; font-weight: bold">RTCDataChannel without signaling</div>
      <div class="big"><a href="http://www.simpl.info/dc" title="Single page RTCDataChannel example">simpl.info/dc</a></div>
    </article>
    <aside class="note">
    </aside>
</slide>

<!--
<slide>
  <hgroup>
    <h2>More information</h2>
  </hgroup>
  <article>
  <ul class='tight'>
    <li>chrome://webrtc-internals</li>
    <li>WebRTC and Web Audio resources list: <a href="http://bit.ly/webrtcwebaudio" title="WebRTC and Web Audio standards, documentation, tutorials, demos, samples and applications">bit.ly/webrtcwebaudio</a></li>
    <li><a href="http://www.youtube.com/watch?v=p2HzZkd2A40" title="Video of Google I/O 2013 WebRTC session on YouTube">Google I/O 2013 WebRTC presentation</a></li>
    <li><a href="http://www.bitbucket.org/webrtc/codelab" title="Step by step WebRTC codelab">Codelab</a>: build a video chat client and Node/Socket.io signaling service</li>
    <li>HTML5 Rocks:</li>
    <ul class='tight'>
      <li><a href="http://www.html5rocks.com/en/tutorials/webrtc/infrastructure/" title="HTML5 Rocks article about WebRTC infrastructure">WebRTC in the real world: STUN, TURN and signaling</a></li>
      <li><a href="http://www.html5rocks.com/en/tutorials/getusermedia/intro/" title="HTML5 Rocks article about getUserMedia">Capturing audio and video in HTML5</a></li>
      <li><a href="http://www.html5rocks.com/en/tutorials/webrtc/basics/" title="HTML5 Rocks article about WebRTC">Getting Started With WebRTC</a></li>
      <li><a href="http://www.html5rocks.com/en/search?q=webrtc" title="HTML5 content tagged WebRTC">Updates</a></li>
    </ul>
    <li>...and a book: <a href="http://www.webrtcbook.com" title="WebRTC ebook download">webrtcbook.com</a></li>
  </ul>
  </article>
<aside class="note">
    <p></p>
  </aside>
</slide>
-->


<slide class="segue dark nobackground">
  <aside class="gdbar"><img src="images/google_developers_icon_128.png"></aside>
  <hgroup class="auto-fadein">
    <h2 style="width: 780px">Audio in the Web Platform</h2>
  </hgroup>
  <aside class="note">
  <p>Now - enough about video. What about audio?</p>
  </aside>
</slide>

<slide class="nobackground">
  <article  class="fill flexbox vcenter">
    <pre class="quiteBig prettyprint" style="background: none;"><a href="http://simpl.info/audio/" title="Audio element demo">&lt;audio src='chrome.mp3' /&gt;</a></code>
  </article>
  <aside class="note">
    <p>This audio element is a thing of simple beauty.</p>
    <p>Loads, decodes and plays audio - just like that!</p>
    <p>Anyone remember the bgsound element? Embedded a sound in the page which started running on page load.</p>
  </aside>
</slide>

<slide>
  <hgroup>
    <h2>Why Web Audio when we have &lt;audio&gt;?</h2>
  </hgroup>
  <article>
  <ul>
    <li>Precise timing of multiple overlapping sounds</li>
    <li>Audio pipeline/routing for effects and filters</li>
    <li>Visualize and manipulate audio data</li>
  </ul>
  </article>
  <aside class="note">
    <p>&lt;audio&gt; for playing 'long' files and streaming</p>
    <p>Timing is particularly important for games - and you need to be able to overlap sounds.</p>
  </aside>
</slide>

<slide>
  <hgroup>
    <h2>Web Audio can do a LOT...</h2>
  </hgroup>
  <article>
    <ul class="tight" style="font-size: 0.82em">
      <li>Oscillators</li>
      <li>Sequences/rhythms/loops</li>
      <li>Fade-ins/fade-outs/sweeps</li>
      <li>Time-based event scheduling</li>
      <li>Frequency and waveform analysis</li>
      <li>Acoustic environments: reverb, etc.</li>
      <li>Waveshaping (non-linear distortion)</li>
      <li>Dynamics processing (compression)</li>
      <li>Filtering effects: radio, telephone, etc.</li>
      <li>Distance attenuation and sound directionality</li>
      <li>Doppler shift: changing pitch for moving sources</li>
      <li>3D spatialization: positioning sound at a particular place</li>
    </ul>
  </article>
  <aside class="note">
  <p>Web Audio has a ton of built in capabilities and effects, and you don't need to be a digital signal processing expert to use it.  I'm certainly not.  I've given lots of web audio talks before, so I'm not going to go into too much depth here...</p>
    <p>Brian Rinaldi has a talk on 8-bit game audio using Web Audio in Salon 14 at noon - right after this talk - so let's all head over there to heckle him.</p>
  </aside>
</slide>

<slide>
  <hgroup>
    <h2>Web Audio status</h2>
  </hgroup>
  <article>
    <ul style="margin-bottom: 1em">
      <li>Chrome desktop and Android &mdash; including gUM input</li>
      <li>Safari 6.0+ and iOS6+</li>
      <li>Firefox 25 desktop and Android</li>
      <li>Mic to speaker latency as low as 5ms</li>
    </ul>
    <div>More information? <a href="http://www.youtube.com/watch?v=wZrNI-86zYI" title="Chris Wilson Web Audio presentation">Web Audio talk</a> <a href="http://webaudiodemos.appspot.com/">demos</a></div>
  </article>
  <aside class="note">
  <p>I did want to update that not only is Web Audio on Chrome and Safari, on desktop, iOS and Android, but also on Firefox on desktop and Android. On Chrome on OSX, we can get mic-to-speaker latency in the 5ms range, too, which is amazing.
  </aside>
</slide>

<slide>
  <hgroup>
    <h2>getUserMedia ☞ Web Audio</h2>
  </hgroup>
  <article>
    <pre class="prettyprint" data-lang="javascript">
// Success callback when requesting audio input stream
function gotStream(stream) {
    var audioContext = new webkitAudioContext();

    // Create an AudioNode from the stream
    <b>var mediaStreamSource = audioContext.createMediaStreamSource(stream);</b>

    // Connect it to the destination or any other node for processing!
    mediaStreamSource.connect(audioContext.destination);
}

navigator.getUserMedia( <b>{audio:true}</b>, gotStream);
</pre>

  </article>
  <aside class="note">
  <p>Speaking of microphones, we can get audio streams from getUserMedia into the system.  I've used this in a number of demos before...</p>
  </aside>
</slide>

<slide class="nobackground">
  <article class="fill flexbox vcenter">
    <div style="margin: 0 0 1em 0; font-weight: bold">gUM + Web Audio + WebGL</div>
    <div><a href="http://www.webaudiodemos.appspot.com/Vocoder/index.html" title="Vocoder">webaudiodemos.appspot.com/Vocoder/</a></div>
  </article>
  <aside class="note">... and ...  try this one at home.
  </aside>
</slide>

<slide>
  <hgroup>
    <h2>gUM ☞ Web Audio ☞ RTCPeerConnection</h2>
  </hgroup>
  <article>
  <p style="margin: 0 0 2em 0">Capture microphone input and stream it to a peer with processing applied:</p>
    <pre class="prettyprint" data-lang="javascript">
navigator.getUserMedia('audio', gotAudio);
function gotAudio(stream) {
  var microphone = context.createMediaStreamSource(stream);
  var filter = context.createBiquadFilter();
  var peer = context.createMediaStreamDestination();
  microphone.connect(filter);
  filter.connect(peer);
  peerConnection.addStream(peer.stream);
}
</pre>
  <div><a href="http://simpl.info/webrtcwebaudio/index.html" title="WebRTC as input to RTCPeerConnection">Demo</a></div>
  <p style="margin: 2em 0 0 0"><a href="https://dvcs.w3.org/hg/audio/raw-file/tip/webaudio/webrtc-integration.html" title="W3C examples adapted from the MediaStream Processing API proposal">More Media Stream integration examples</a></p>
  </article>
  <aside class="note">
    <p>We can also integrate this with WebRTC - and apply effects like the vocoder on audio that's fed into an RTCPeerConnection.</p>
  </aside>
</slide>

<slide>
  <hgroup>
    <h2>Web MIDI</h2>
  </hgroup>
  <article>
  <ul>
    <li>New proposed standard</li>
    <li>Standard MIDI files: not just cheesy background music!</li>
    <li>Connect controllers, synthesizers and more</li>
    <li>Implemented in Chrome behind a flag - Mac, Windows, Linux, ChromeOS and Android!</li>
  </ul>
  </article>
  <aside class="note">
  <p>I also want to mention another nascent standard - the Web MIDI API.  
  </aside>
</slide>

<slide>
  <article class="fill flexbox vcenter">
    <div style="margin: 0 0 2em 0; font-weight: bold">Synths and drum machines</div>
    <div class="biggish" style="margin: 0 0 1em 0;"><a href="http://webaudiodemos.appspot.com/MIDIDrums/index.html" title="MIDI drum machine demo">MIDI drums</a></div>
    <div class="biggish" style="margin: 0 0 1em 0;"><a href="http://webaudiodemos.appspot.com/midi-synth/index.html" title="MIDI synth">MIDI synth</a></div>
    <div class="biggish" style="margin: 0 0 2em 0;"><a href="http://gridflux.googlecode.com/git/index.html" title="Gidflux synth">GRIDFLUX</a></div>
    <div class="biggish" style="margin: 0 0 2em 0;"><a href="http://yamaha-webmusic.github.io/" title="Yamaha github">Yamaha NSX-1</a></div>

    <div style="margin: 0 0 1.5em 0;"><a href="http://flippinawesome.org/2013/10/28/audio-synthesis-in-javascript/" title="Gidflux synth">Audio synthesis in JavaScript</a></div>
  </article>
  <aside class="note">
  </aside>
</slide>



<!-- FUTURE
<slide>
  <hgroup>
    <h2>Media Stream Recording API</h2>
  </hgroup>
  <article>
  <ul>
    <li>Demo: <a href="http://simpl.info/mediarecorder" title="Media Stream Recording demo">simpl.info/mediarecorder</a></li>
    <li><a href="https://dvcs.w3.org/hg/dap/raw-file/default/media-stream-capture/MediaRecorder.html" title="W3C MediaRecorder draft spec">Spec</a></li>
    <li>Chrome <a href="https://groups.google.com/a/chromium.org/forum/?fromgroups=#!topic/blink-dev/2l_G_apqk30" title="blink-dev Media Stream Recording API Intent to Implement discussion">Intent to Implement</a></li>
    <li><a href="http://www.w3.org/TR/streams-api/" title="W3C Streams API draft spec">Streams API</a></li>
  </ul>
  </article>
  <aside class="note">
    <p>Needs Firefox!</p>
    <p>How does it work? A MediaRecorder is created which takes an audio stream from navigator.getUserMedia(). When a blob of recorded data becomes available (set to occur after two seconds) this is used to set the src of the audio element, using window.URL.createObjectURL().</p>
  </aside>
</slide>

<slide>
  <hgroup>
    <h2>Media Stream Image Capture API</h2>
  </hgroup>
  <article>
  <ul>
    <li><del>Demo</del></li>
    <li><a href="http://gmandyam.github.io/image-capture/" title="W3C Media Stream Image Capture draft spec">Spec</a></li>
    <li><code>getFrame()</code> creates an <code>ImageData</code> object available in <code>onframegrab</code></li>
    <li><code>takePhoto()</code> creates a Blob available in <code>onphoto</code></li>
  </ul>
  </article>
  <aside class="note">
    <p>This is essentially an API for taking photos.</p>
    <p>The intention is to give access to camera controls such as autofocus and zoom.</p>
  </aside>
</slide>

-->
<slide class="thank-you-slide segue nobackground">
  <aside class="gdbar right"><img src="images/google_developers_icon_128.png"></aside>
  <article class="flexbox vleft auto-fadein">
    <h2>&lt;/talk&gt;</h2>
    <h3>Thank You!</h3>
      <p style="font-size:1.2em; margin-bottom: 2em">Slides: &nbsp;<a href="goo.gl/lzhB1Y" style="color:inherit" title="These slides online">goo.gl/lzhB1Y</a></p>
  </article>

  <p class="auto-fadein" data-config-contact>
    <!-- populated from slide_config.json -->
  </p>
      <aside class="note">
    Once again, the link to the slides.
    </aside>
</slide>


<slide class="backdrop"></slide>

</slides>

<!--[if IE]>
  <script src="http://ajax.googleapis.com/ajax/libs/chrome-frame/1/CFInstall.min.js"></script>
  <script>CFInstall.check({mode: 'overlay'});</script>
<![endif]-->
</body>
</html>
